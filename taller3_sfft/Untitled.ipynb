{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codec de compresión de audio\n",
    "\n",
    "El siguiente código implementa un codec sencillo de compresión de\n",
    "audio. El resultado es positivo reduciendo el peso del archivo\n",
    "conservando buena parte de la calidad del audio original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boterock\\Anaconda3\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" >\n",
       "                    <source src=\"01_original_mono.wav\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyaudio\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from bokeh.io import curdoc\n",
    "from bokeh.plotting import Figure, ColumnDataSource\n",
    "from bokeh.layouts import column\n",
    "from bokeh.client import push_session\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import IPython\n",
    "\n",
    "#cargar audio a procesar\n",
    "\n",
    "input_file = \"sax.wav\"\n",
    "fs, wav = wavfile.read(input_file)\n",
    "\n",
    "# seleccionar solo canal izquierdo para procesamiento\n",
    "wav = wav[:, 0]\n",
    "\n",
    "wavfile.write(\"01_original_mono.wav\", fs, wav)\n",
    "\n",
    "IPython.display.Audio(url=\"01_original_mono.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio controls=\"controls\">\n",
    "                    <source src=\"01_original_mono.wav\" type=\"audio/wav\">\n",
    "                    Your browser does not support the audio element.\n",
    "                </audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''  Este codigo funciona individualmente en el archivo test_pyaudio.py, aca esta provisionammente mientras se organiza en el notebook.\n",
    "sample_rate = 44100\n",
    "timestep = 1 / sample_rate\n",
    "\n",
    "t = np.arange(0, 1024)\n",
    "y = np.sin(t)\n",
    "\n",
    "f = np.fft.rfftfreq(y.size, timestep)\n",
    "fft = np.absolute(np.fft.rfft(y))\n",
    "\n",
    "sound_data = ColumnDataSource(data=dict(t=t, y=y))\n",
    "fft_data = ColumnDataSource(data=dict(f=f, fft=fft))\n",
    "\n",
    "\n",
    "def update():\n",
    "    global f, fft\n",
    "    f = np.fft.rfftfreq(y.size, timestep)\n",
    "    # fft = np.absolute(np.fft.rfft(y))\n",
    "\n",
    "    # fft[fft < FOURIER_CUTOFF] = 0\n",
    "\n",
    "    sound_data.data[\"t\"] = t\n",
    "    sound_data.data[\"y\"] = y\n",
    "    fft_data.data[\"f\"] = f\n",
    "    fft_data.data[\"fft\"] = np.absolute(fft)\n",
    "\n",
    "\n",
    "figure_limit = (-35000, 35000)  # i16 min to i16 max\n",
    "sound_figure = Figure(plot_width=1024, plot_height=400, y_range=figure_limit)\n",
    "sound_figure.line(x=\"t\", y=\"y\", source=sound_data)\n",
    "\n",
    "fft_figure = Figure(plot_width=1024, plot_height=400, y_range=(0, 800000))\n",
    "fft_figure.line(x=\"f\", y=\"fft\", source=fft_data)\n",
    "\n",
    "document = curdoc()\n",
    "document.add_root(column(sound_figure, fft_figure))\n",
    "session = push_session(document)\n",
    "session.show()\n",
    "\n",
    "# Refresh rate set to 30 hz\n",
    "document.add_periodic_callback(update, 1000 / 30)\n",
    "\n",
    "pa = pyaudio.PyAudio()\n",
    "\n",
    "use_sound_file = True\n",
    "input_file = \"sax.wav\"\n",
    "\n",
    "fs, wav = wavfile.read(input_file)\n",
    "wav = wav[:, 0]\n",
    "# wav = wav.astype(np.float32, order='C') / 32768.0\n",
    "wav = wav.astype(np.int16, order='C')\n",
    "\n",
    "head = 0\n",
    "buff_size = 1024\n",
    "\n",
    "sample_rate = fs\n",
    "timestep = 1 / sample_rate\n",
    "PA_FORMAT = pyaudio.paInt16 if wav.dtype == np.int16 else pyaudio.paFloat32\n",
    "\n",
    "FOURIER_CUTOFF = 8e4  # try 2k to 20k\n",
    "\n",
    "\n",
    "def compress_rle(in_bytes, encode_element):\n",
    "    count = 0\n",
    "    output = bytearray()\n",
    "    for b in in_bytes:\n",
    "        if count == 255:\n",
    "            output.append(encode_element)\n",
    "            output.append(255)\n",
    "            count = 0\n",
    "\n",
    "        if b == encode_element:\n",
    "            count += 1\n",
    "        else:  # if the new element should not be encoded\n",
    "            if count > 0:\n",
    "                output.append(encode_element)\n",
    "                output.append(count)\n",
    "                count = 0\n",
    "\n",
    "            output.append(b)\n",
    "\n",
    "    if count > 0:\n",
    "        output.append(encode_element)\n",
    "        output.append(count)\n",
    "        count = 0\n",
    "    return bytes(output)\n",
    "\n",
    "\n",
    "def uncompress_rle(in_bytes, encode_element):\n",
    "    output = bytearray()\n",
    "    for idx, b in enumerate(in_bytes):\n",
    "        if b is encode_element:\n",
    "            continue\n",
    "        if idx == 0:\n",
    "            output.append(b)\n",
    "        elif in_bytes[idx - 1] == encode_element:\n",
    "            output.extend([encode_element] * b)\n",
    "        else:\n",
    "            output.append(b)\n",
    "\n",
    "    return bytes(output)\n",
    "\n",
    "\n",
    "def callback(in_data, frame_count, time_info, flag):\n",
    "\n",
    "    global y, t, head, fft\n",
    "    data = None\n",
    "\n",
    "    if use_sound_file:\n",
    "        data = wav[head:head + buff_size]\n",
    "        head += buff_size\n",
    "        y = data\n",
    "        t = np.arange(y.size)\n",
    "\n",
    "        fft_temp = np.fft.rfft(y)\n",
    "\n",
    "        # encode\n",
    "\n",
    "        fft_abs = np.absolute(fft_temp)\n",
    "        fft_temp[fft_abs < FOURIER_CUTOFF] = np.complex(0)\n",
    "\n",
    "        fft_temp = fft_temp.view(np.float64)\n",
    "\n",
    "        fft_temp = fft_temp / 8000\n",
    "\n",
    "        fft_temp = fft_temp.astype(np.int16)\n",
    "\n",
    "        bytes_data = fft_temp.tobytes()\n",
    "\n",
    "        bytes_compressed = compress_rle(bytes_data, 0)\n",
    "\n",
    "        bytes_uncompressed = uncompress_rle(bytes_compressed, 0)\n",
    "\n",
    "        len_data = len(bytes_data)\n",
    "        len_compressed = len(bytes_compressed)\n",
    "        ratio = len_compressed / len_data\n",
    "\n",
    "        print(\"len data: {}, Compressed: {},  final size: {}\", len_data,\n",
    "              len_compressed, ratio)\n",
    "\n",
    "        fft_temp = np.frombuffer(bytes_uncompressed, np.int16)\n",
    "        print(\"fft_temp shape\", fft_temp.shape)\n",
    "        # decode\n",
    "        fft_temp = fft_temp.astype(np.float64)\n",
    "\n",
    "        fft_temp = fft_temp * 8000\n",
    "        fft_temp = fft_temp.view(np.complex128)\n",
    "\n",
    "        fft = fft_temp\n",
    "\n",
    "        y = np.fft.irfft(fft_temp, buff_size)\n",
    "        data = y.astype(np.int16, order='C')\n",
    "\n",
    "    else:\n",
    "        y = np.fromstring(data, dtype=wav.dtype)\n",
    "        t = np.arange(y.size)\n",
    "\n",
    "    return (data, pyaudio.paContinue)\n",
    "\n",
    "\n",
    "default_device = pa.get_default_output_device_info()\n",
    "\n",
    "stream = pa.open(\n",
    "    format=PA_FORMAT,\n",
    "    channels=1,\n",
    "    rate=sample_rate,\n",
    "    output=use_sound_file,\n",
    "    input=~use_sound_file,\n",
    "    stream_callback=callback,\n",
    "    output_device_index=default_device['index'])\n",
    "\n",
    "stream.start_stream()\n",
    "\n",
    "session.loop_until_closed()\n",
    "\n",
    "while stream.is_active():\n",
    "    time.sleep(0.25)\n",
    "stream.close()\n",
    "pa.terminate()\n",
    "'''\n",
    "\n",
    "''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
